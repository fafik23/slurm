<!--#include virtual="header.txt"-->

<h1>Heterogeneous Job Support</h1>

<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#submitting">Submitting Jobs</a></li>
<li><a href="#managing">Managing Jobs</a></li>
<li><a href="#job_steps">Launching Applications (Job Steps)</a></li>
<li><a href="#env_var">Environment Variables</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#sys_admin">System Administrator Information</a></li>
</ul>

<h2><a name="overview">Overview</a></h2>

<p>Slurm version 17.11 and later supports the ability to submit and manage
heterogeneous jobs, in which each component has virtually all job options
available including partition, account and QOS (Quality Of Service).
For example, part of a job might require four cores and 4 GB for each of 128
tasks while another part of the job would require 16 GB of memory and one CPU.</p>

<h2><a name="submitting">Submitting Jobs</a></h2>

<p>The <i>salloc</i>, <i>sbatch</i> and <i>srun</i> commands can all be used
to submit heterogeneous jobs.
Resource specifications for each component of the heterogeneous job should be
separated with ":" character.
For example:</p>
<pre>
$ sbatch --cpus-per-task=4 --mem-per-cpu=1  --ntasks=128 : \
         --cpus-per-task=1 --mem-per-cpu=16 --ntasks=1 my.bash
</pre>

<p>Options specified for one component of a heterogeneous job (or job step) will
be used for subsequent components to the extent which is expected to be helpful.
Propagated options can be reset as desired for each component (e.g. a different
account name could be specified for each job component.
For example, <i>--immediate</i> and <i>--job-name</i> are propagated, while
<i>--ntasks</i> and <i>--mem-per-cpu</i> are reset to default values for each
component.
A list of propagated options follows.</p>
<ul>
<li>--account</li>
<li>--acctg-freq</li>
<li>--begin</li>
<li>--checkpoint</li>
<li>--checkpoint-dir</li>
<li>--cluster-constraint</li>
<li>--clusters</li>
<li>--comment</li>
<li>--deadline</li>
<li>--delay-boot</li>
<li>--dependency</li>
<li>--epilog            (option available only in srun)</li>
<li>--error</li>
<li>--export</li>
<li>--export-file</li>
<li>--exclude</li>
<li>--get-user-env</li>
<li>--gid</li>
<li>--hold</li>
<li>--ignore-pbs</li>
<li>--immediate</li>
<li>--input</li>
<li>--job-name</li>
<li>--kill-on-bad-exit  (option available only in srun)</li>
<li>--label             (option available only in srun)</li>
<li>--max-exit-timeout  (option available only in srun)</li>
<li>--mcs-label</li>
<li>--msg-timeout       (option available only in srun)</li>
<li>--no-allocate       (option available only in srun)</li>
<li>--no-requeue</li>
<li>--nice</li>
<li>--no-kill</li>
<li>--open-mode         (option available only in srun)</li>
<li>--output</li>
<li>--parsable</li>
<li>--priority</li>
<li>--profile</li>
<li>--propagate</li>
<li>--prolog            (option available only in srun)</li>
<li>--pty               (option available only in srun)</li>
<li>--qos</li>
<li>--quiet</li>
<li>--quit-on-interrupt (option available only in srun)</li>
<li>--reboot</li>
<li>--reservation</li>
<li>--requeue</li>
<li>--signal</li>
<li>--slurmd-debug      (option available only in srun)</li>
<li>--task-epilog       (option available only in srun)</li>
<li>--task-prolog       (option available only in srun)</li>
<li>--time</li>
<li>--test-only</li>
<li>--time-min</li>
<li>--uid</li>
<li>--unbuffered        (option available only in srun)</li>
<li>--verbose</li>
<li>--wait</li>
<li>--wait-all-nodes</li>
<li>--wckey</li>
<li>--workdir</li>
</ul>

<p>Environment variables used to specify default options for the job submit
command will be applied to every component of the heterogeneous job
(e.g. <i>SBATCH_ACCOUNT</i>).</p>

<p>Batch job options can be included in the submitted script for multiple
heterogeneous job components. Each component should be separated by a line
containing the line "#SBATCH packjob" as shown below.</p>
<pre>
$ cat new.bash
#!/bin/bash
#SBATCH --cpus-per-task=4 --mem-per-cpu=16g --ntasks=1
#SBATCH packjob
#SBATCH --cpus-per-task=2 --mem-per-cpu=1g  --ntasks=8

srun run.app

$ sbatch new.bash
</pre>

<p>Is equivalent to the following:</p>

<pre>
$ cat my.bash
#!/bin/bash
srun run.app

$ sbatch --cpus-per-task=4 --mem-per-cpu=16g --ntasks=1 : \
         --cpus-per-task=2 --mem-per-cpu=1g  --ntasks=8 my.bash
</pre>

<p>The batch script will be executed in the first node in the first component
of the heterogeneous job. For the above example, that will be the job component
with 1 task, 4 CPUs and 64 GB of memory (16 GB for each of the 4 CPUs).</p>

<p>If a heterogeneous job is submitted to run in multiple clusters <u>not</u>
part of a federation (e.g. "sbatch --cluster=alpha,beta ...") then the entire
job will be sent to the cluster expected to be able to start all components
at the earliest time.</p>

<p>A resource limit test is performed when a heterogeneous job is submitted in
order to immediately reject jobs that will not be able to start with current
limits.
The individual components of the heterogeneous job are validated, like all
regular jobs.
The heterogeneous job as a whole is also tested, but in a more limited
fashion with respect to quality of service (QOS) limits.
Each component of a heterogeneous job counts as a "job" with respect to
resource limits.</p>

<h2><a name="managing">Managing Jobs</a></h2>

<p>Information maintained in Slurm for a heterogeneous job includes:</p>
<ul>
<li><i>job_id</i>: Each component of a heterogeneous job will have its own
unique <i>job_id</i>.</li>
<li><i>pack_job_id</i>: This identification number applies to all components
of the heterogeneous job. All components of the same job will have the same
<i>pack_job_id</i> value and it will be equal to the <i>job_id</i> of the
first component. We refer to this as the "pack leader".</li>
<li><i>pack_job_id_set</i>: Regular expression identifying all <i>job_id</i>
values associated with the job.</li>
<li><i>pack_job_offset</i>: A unique sequence number applied to each component
of the heterogeneous job. The first component will have a <i>>pack_job_offset</i>
value of 0, the next a value of 1, etc.</li>
</ul>

<table width="100%" border=1 cellspacing=0 cellpadding=4>
<tr>
  <th width="25%"><b>job_id</b></th>
  <th width="25%"><b>pack_job_id</b></th>
  <th width="25%"><b>pack_job_offset</b></th>
  <th width="25%"><b>pack_job_id_set</b></th>
 </tr>

<tr><td>123</td><td>123</td><td>0</td><td>123-127</td></tr>
<tr><td>124</td><td>123</td><td>1</td><td>123-127</td></tr>
<tr><td>125</td><td>123</td><td>2</td><td>123-127</td></tr>
<tr><td>126</td><td>123</td><td>3</td><td>123-127</td></tr>
<tr><td>127</td><td>123</td><td>4</td><td>123-127</td></tr>
</table>
<p>Table 1: Example job IDs</p>

<p>The <i>smap</i>, <i>smap</i>, <i>squeue</i> and <i>sview</i> report the
components of a heterogeneous job using the format
"&lt;pack_job_id&gt;+&lt;pack_job_offset&gt;".
For example "123+4" would represent heterogeneous job id 123 and it's fifth
component (note: the first component has a <i>pack_job_offset</i> value of 0).</p>

<p>A request for a specific job ID that identifies a ID of the first component
of a heterogeneous job (i.e. the "pack leader" will return information about
all components of that job. For example:</p>
<pre>
$ squeue --job=93
JOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST
 93+0     debug  bash  adam  R 18:18      1 nid00001
 93+1     debug  bash  adam  R 18:18      1 nid00011
 93+2     debug  bash  adam  R 18:18      1 nid00021
</pre>

<p>A request to cancel or otherwise signal a pack leader will be applied to
all components of that pack job. A request to cancel a specific component of
the pack job using the "#+#" notation will apply on to that specific component.
For example:</p>
<pre>
$ squeue --job=93
JOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST
 93+0     debug  bash  adam  R 19:18      1 nid00001
 93+1     debug  bash  adam  R 19:18      1 nid00011
 93+2     debug  bash  adam  R 19:18      1 nid00021
$ scancel 93+1
$ squeue --job=93
JOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST
 93+0     debug  bash  adam  R 19:38      1 nid00001
 93+2     debug  bash  adam  R 19:38      1 nid00021
$ scancel 93
$ squeue --job=93
JOBID PARTITION  NAME  USER ST  TIME  NODES NODELIST
</pre>

<p>Email notification for job state changes (the <i>--mail-type</i> option)
is only supported for a pack leader. Requests for email notifications for other
components of a heterogeneous job will be silently ignored.</p>

<p>Requests to perform the following operations a job can only be requested for
a pack leader and will be applied to all components of that heterogeneous job.
Requests to operate on individual components of the heterogeneous will return
an error.</p>
<ul>
<li>requeue</li>
<li>resume</li>
<li>suspend</li>
</ul>

<h3>Accounting</h3>

<p>Slurm's accounting database records the pack_job_id and pack_job_offset
fields.
The sacct command reports job's using the format
"&lt;pack_job_id&gt;+&lt;pack_job_offset&gt;" and can accept a job ID
specification for filtering using the same format.
If a pack_job_id value is specified as a job filter, then information about
all components of that job will be reported as shown below.</p>

<pre>
$ sacct -j 67767+1
  JobID JobName Partition Account AllocCPUS     State ExitCode 
------- ------- --------- ------- --------- --------- -------- 
67767+0     foo     debug    test         2 COMPLETED      0:0 
67767+1     foo     debug    test         4 COMPLETED      0:0 

$  sacct -j 67767+1
  JobID JobName Partition Account AllocCPUS     State ExitCode 
------- ------- --------- ------- --------- --------- -------- 
67767+1     foo     debug    test         4 COMPLETED      0:0 
</pre>

<h2><a name="job_steps">Launching Applications (Job Steps)</a></h2>

<p>The srun command is used to launch applications.
By default, the application is launched only on the first component of a
heterogeneous job, but options are available to support different behaviors.</p>

<p>srun's "--pack-group" option defines which pack job component(s) are to have
applications launched for them. The --pack-group option takes an expression
defining which component(s) are to launch an application for an individual
execution of the srun command. The expression can contain one or more component
index values in a comma separated list. Ranges of index values can be specified
in a hyphen separated list. By default, an application is launched only on
component number zero. Some examples follow:</p>
<ul>
<li>--pack-group=2</li>
<li>--pack-group=0,4</li>
<li>--pack-group=1,3-5</li>
</ul>

<p>By default, the applications launched by a single execution of the srun
command (even for different components of the heterogeneous job) are combined
into one MPI_COMM_WORLD with non-overlapping task IDs. srun's "--mpi-combine=no"
option will launch each component in the heterogeneous job in its own
MPI_COMM_WORLD with a task ID starting at zero.</p>

<p>srun's "--label" option will precede every line with the letter "P" and
pack job offset followed by the task rank if the "--mpi-combine=no" option is
used or a the application is launched on a subset of pack groups
For example:</p>
<pre>
$ srun --mpi-combine=no -n2 hostname : -n1 date
P0 0: nid00012
P0 1: nid00012
P1 0: Wed Jul  5 16:23:07 MDT 2017
</pre>

<h2><a name="env_var">Environment Variables</a></h2>

<p>Slurm environment variables will be set independently for each component of
the job by appending "_PACK_GROUP_" and a sequence number the the usual name.
In addition, the "SLURM_JOB_ID" environment variable will contain the job ID
of the pack leader and "SLURM_PACK_SIZE" will contain the number of components
in the job. For example:</p>
<pre>
$  salloc -N1 : -N2 bash
salloc: Pending job allocation 11741
salloc: job 11741 queued and waiting for resources
salloc: job 11741 has been allocated resources
$ env | grep SLURM
SLURM_JOB_ID=11741
SLURM_PACK_SIZE=2
SLURM_JOB_ID_PACK_GROUP_0=11741
SLURM_JOB_ID_PACK_GROUP_1=11742
SLURM_NNODES_PACK_GROUP_0=1
SLURM_NNODES_PACK_GROUP_1=2
SLURM_JOB_NODELIST_PACK_GROUP_0=nid00001
SLURM_JOB_NODELIST_PACK_GROUP_1=nid[00011-00012]
...
</pre>

<h2><a name="examples">Examples</a></h2>

<p>Create a heterogeneous resource allocation containing one node with 256GB
of memory and a feature of "haswell" plus 2176 cores on 32 nodes with a
feature of "knl". Then launch a program called "master" on the "haswell" node
and "slave" on the "knl" nodes. Each application will be in its own
MPI_COMM_WORLD.</p>
<pre>
salloc -N1 --mem=256GB -C haswell : \
       -n2176 -N32 --ntasks-per-core=1 -C knl bash
srun master &
srun --pack-group=1 slave &
wait
</pre>

<p>This variation of the above example launches programs "master" and "slave"
in a single MPI_COMM_WORLD.</p>
<pre>
salloc -N1 --mem=256GB -C haswell : \
       -n2176 -N32 --ntasks-per-core=1 -C knl bash
srun master : slave &
</pre>

<h2><a name="limitations">Limitations</a></h2>

<p>In a federation of clusters, a heterogeneous job will execute entirely on
the cluster from which the job is submitted. The heterogeneous job will not
be eligible to migrate between clusters or to have different components of
the job execute on different clusters in the federation.</p>

<p>Job arrays of heterogeneous jobs are not supported.</p>

<p>The srun command's --no-allocate option is not supported
for heterogeneous jobs.</p>

<p>Only one job step per heterogeneous job component can be launched by a
single srun command (e.g.
"srun --pack-group=0 alpha : --pack-group=0 beta" is not supported).</p>

<p>The sattach command can only be used to attach to a single component of
a heterogeneous job at a time.</p>

<p>Heterogeneous jobs are only scheduled by the backfill scheduler plugin.
The more frequently executed scheduling logic only starts jobs on a first-in
first-out (FIFO) basis and lacks logic for concurrently scheduling all
components of a heterogeneous job.</p>

<p>Heterogeneous jobs are not supported with Slurm's select/serial plugin.</p>

<p>Heterogeneous jobs are not supported Cray ALPS systems.</p>

<h2><a name="sys_admin">System Administrator Information</a></h2>

<p>The job submit plugin is invoked independently for each component of a
heterogeneous job.</p>

<p>Scheduling of heterogeneous jobs is performed only by the sched/backfill
plugin and all heterogeneous job components are either all scheduled at the same
time or deferred.
In order to insure the timely initiation of both heterogeneous and
non-heterogeneous jobs, the backfill scheduler alternates between two different
modes on each iteration.
In the first mode, if a heterogeneous job component can not be initiated
immediately, its expected start time is recorded and all subsequent components
of that job will be considered for starting no earlier than the latest
component's expected start time.
In the second mode, all heterogeneous job components will be considered for
starting no earlier than the latest component's expected start time.
After completion of the second mode, all heterogeneous job expected start time
data is cleared and the first mode will be used in the next backfill scheduler
iteration.
Regular (non-heterogeneous jobs) are scheduled independently on each iteration
of the backfill scheduler.</p>

<p> For example, consider a heterogeneous job with three components.
When considered as independent jobs, the components could be initiated at times
now (component 0), now plus 2 hour (component 1), and now plus 1 hours
(component 2).
When the backfill scheduler runs in the first mode:</p>
<ol>
<li>Component 0 will be noted to possible to start now, but not initiated due
to the additional components to be initiated</li>
<li>Component 1 will be noted to be possible to start in 2 hours</li>
<li>Component 2 will not be considered for scheduling until 2 hours in the
future, which leave some additional resources available for scheduling to other
jobs</li>
</ol>

<p>When the backfill scheduler executes next, it will use the second mode and
(assuming no other state changes) all three job components will be considered
available for scheduling no earlier than 2 hours in the future, which may allow
other jobs to be allocated resources before heterogeneous job component 0
could be initiated.</p>

<p>The heterogeneous job start time data will be cleared before the first
mode is used in the next iteration in order to consider system status changes
which might permit the heterogeneous to be initiated at an earlier time than
previously determined.</p>

<p>A resource limit test is performed when a heterogeneous job is submitted in
order to immediately reject jobs that will not be able to start with current
limits.
The individual components of the heterogeneous job are validated, like all
regular jobs.
The heterogeneous job as a whole is also tested, but in a more limited
fashion with respect to quality of service (QOS) limits.
This is due to the complexity of each job component having up to three sets of
limits (association, job QOS and partition QOS).
Note that successful submission of any job (heterogeneous or otherwise) does
not insure the job will be able to start without exceeding some limit.
For example a job's CPU limit test does not consider that CPUs might not be
allocated individually, but resource allocations might be performed by whole
core, socket or node.
Each component of a heterogeneous job counts as a "job" with respect to
resource limits.</p>

For example, a user might have a limit of 2 concurrent running jobs and submit
a heterogeneous job with 3 components.
Such a situation will have an adverse effect upon scheduling other jobs,
especially other heterogeneous jobs.</p>

<p class="footer"><a href="#top">top</a></p>

<p style="text-align:center;">Last modified 2 August 2017</p>

<!--#include virtual="footer.txt"-->
